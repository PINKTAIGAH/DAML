{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workshop 1: excersices for practice\n",
    "\n",
    "This workshops 1 problems are not assessed and are intended for practicing the the concepts introduced in the 1st ML lecture, the and the notebooks `data-science-tools.ipynb` and `lecture2.ipynb`. \n",
    "\n",
    "It is recommended that you go thorugh those notebooks 1st and try to understand each line before jumping into the excersises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Responsible:* Robert Currie (<rob.currie@ed.ac.uk>) borrowed from Guillermo Hamity\n",
    "\n",
    "## Wine quality dataset\n",
    "\n",
    "The [wine quality dataset](https://archive.ics.uci.edu/ml/datasets/wine%20quality) will be analysed\n",
    "\n",
    "***Before*** we begin you will need to copy the dataset `wine_quality.csv` into the same directory as you're running this notebook!\n",
    "\n",
    "### Dataset information\n",
    "Two datasets were created, using red and white wine samples.\n",
    "The inputs include objective tests (e.g. PH values) and the output is based on sensory data\n",
    "(median of at least 3 evaluations made by wine experts). Each expert graded the wine quality \n",
    "between 0 (very bad) and 10 (very excellent). \n",
    "  \n",
    "1. Number of Instances: red wine - 1599; white wine - 4898. \n",
    "\n",
    "2. Number of Attributes: 11 + output attribute\n",
    "  \n",
    "   Note: several of the attributes may be correlated, thus it makes sense to apply some sort of\n",
    "   feature selection.\n",
    "\n",
    "3. Attribute information:\n",
    "\n",
    "   For more information, read [Cortez et al., 2009].\n",
    "\n",
    "   Input variables (based on physicochemical tests):\n",
    "   1. fixed acidity\n",
    "   \n",
    "   2. volatile acidity\n",
    "   \n",
    "   3. citric acid\n",
    "   \n",
    "   4. residual sugar\n",
    "   \n",
    "   5. chlorides\n",
    "   \n",
    "   6. free sulfur dioxide\n",
    "   \n",
    "   7. total sulfur dioxide\n",
    "   \n",
    "   8. density\n",
    "   \n",
    "   9. pH\n",
    "   \n",
    "   10. sulphates\n",
    "   \n",
    "   11. alcohol\n",
    "   \n",
    "   12. type (R=red, W=white)\n",
    "   \n",
    "   Output variable (based on sensory data): \n",
    "   12 - quality (score between 0 and 10)\n",
    "\n",
    "### Purpose:\n",
    "\n",
    "We will design a model which predicts the quality of **RED** wine based on the input features. In order to achive this we will perform some initial investigations, preperation, and visiualisation of the data. We will then train decition trees to distinguish good vs bad  **red** wines, and check the validity of our model on a testing dataset.\n",
    "\n",
    "### Working through the problems\n",
    "* Try and calculate the answers provided. \n",
    "* Keep code understandable and reproducible, i.e. the notebook can be **restarted** and **re-run**. You will need to do this when work is marked, so better to start practicing.\n",
    "* If you are unsure on how to proceed please reference the two companion notebooks for relevant examples, or **ask one of the TAs**\n",
    "\n",
    "### Notes on solution\n",
    "* This CP exercise sheet is divided into three sections, corresponding to parts of the lecture. The problems will **not** be marked.\n",
    "  - Data science tools \n",
    "  - Visualisation \n",
    "  - Decision tree classification + ensemble methods\n",
    "* Exercises 1-5 can be solved with one line of code while still being legible. _(That's not a weird flex, nor required, just letting you know that if you find yourself with a 20-line long solution, it can probably be done in a simpler way.)_\n",
    "* The following `pandas.DataFrame` functions may be useful: `head`, `describe`, `loc`, `query`, `unique`, `value_counts`, `sort_values`, `group_by`, `apply`, `transform`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Turn off some warnings which we can ignore for this example\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# Standard import(s)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "from sklearn import datasets\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load wine dataset\n",
    "obs = pd.read_csv('wine_quality.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show available properties of the dataset\n",
    "obs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show dataset description\n",
    "obs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicate measurements -- makes sense in this case, since measurements \n",
    "# with identical rows would imply identical wines (at least in composition),\n",
    "# which would be double counted in the dataset\n",
    "obs = obs.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Data science tools \n",
    "\n",
    "This section covers exercises on data handling using pandas.DataFrames.\n",
    "###### 1. How many observations have been collected and how many features are listed per observation? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs.count(numeric_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 2. How may wines are of each type, Red  and White?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs[\"type\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 3. What are the minimum and maximum wine qualities in the dataset ? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs.groupby(\"type\")[\"quality\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 4. Which type of wine (red or white) has the higher score on average ? \n",
    "_Hints:_\n",
    "1. Group the data by type, ie, white and red wine\n",
    "2. Get the mean of the quality for each type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs.groupby(\"type\")[\"quality\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. How many measurements are there for each quality value per wine type?\n",
    "Hits:\n",
    "- group the data by type and quality\n",
    "- count the values in each group\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs.groupby(\"type\")[\"quality\"].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Data preperation\n",
    "\n",
    "From the investigation above we can see varying statistics between the red and white wines. Lets prepare the data in such a way that we define good and bad quality wines based on the median value of each wine type.\n",
    "\n",
    "Make two datasets named `white` and `red` by doing the following\n",
    "\n",
    "1. goup the data into Red and White wine\n",
    "2. find the median values of quality for red and white wines seperately\n",
    "3. create a new quality variable `good_qual` which is 0 for bad (less than the median) and 1 for good (more than or equal to the median)\n",
    "4. drop columns `quality` and `type` from the datasets as they are no longer needed. Use the `drop` method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find median value\n",
    "red_median = obs.groupby(\"type\").median()[\"quality\"]['R']\n",
    "white_median = obs.groupby(\"type\").median()[\"quality\"]['W']\n",
    "\n",
    "# make two seperate dataframes\n",
    "red = obs[ obs[\"type\"] == 'R' ]\n",
    "white = obs[ obs[\"type\"] == 'W' ]\n",
    "\n",
    "# Create Series constaining the good_qual feature for each sample\n",
    "good_qual_red = red[\"quality\"] >= red_median\n",
    "good_qual_white = white[\"quality\"] >= white_median\n",
    "\n",
    "\n",
    "# Include good_qual featuire in the corresponding dataframe\n",
    "red[\"good_qual\"] = good_qual_red.astype(int)\n",
    "white[\"good_qual\"] = good_qual_white.astype(int)\n",
    "\n",
    "# Drop the quality collums\n",
    "red = red.drop(columns=[\"quality\", \"type\"])\n",
    "white = white.drop(columns=[\"quality\", \"type\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## From here on we will be focusing on the **red** wine dataset\n",
    "\n",
    "--------------------------------------------------------\n",
    "###### 7.  Use the describe method to show statistics per good/bad wine in the red wine dataset for alcohol and sulphates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"alcohol\", \"sulphates\"]\n",
    "red.groupby(\"good_qual\")[features].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Visualisation \n",
    "---\n",
    "This section covers 2 exercises on visualisation using `matplotlib.pyplot`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 8 Make a correlation plot of all the features in the red wine dataset\n",
    "- Use the porvided colormap\n",
    "- Use the sns.heatmap function as shown in the lecture\n",
    "- set the tick labels to represent the feature names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the following courmap in as the cmap parameter of sns.heatmap:\n",
    "colormap = sns.diverging_palette(220, 10, as_cmap=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_corrolation = red.corr()\n",
    "sns.heatmap(red_corrolation, annot=False, cmap=colormap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 9 Pick the top five most correlated features to chlorides and make a pairplot split by good_qual\n",
    "\n",
    "- Do not include \"good_qual\" in the calculation of most correlated\n",
    "- Negative and positive correlations both show strong correlation (or anti correlation). Use the ablsolute value to pick the most correlated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_corrolation[red_corrolation[\"chlorides\"].abs() < 1.0][\"chlorides\"].abs().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "top_correlations = [\"alcohol\", \"density\", \"total_sulfur_dioxide\", \"citric_acid\", \"free_sulfur_dioxide\"]\n",
    "\n",
    "top_correlations_dataframe = red[top_correlations + [\"good_qual\"]]\n",
    "sns.pairplot(top_correlations_dataframe, hue=\"good_qual\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Make a scatter plot of the two most correlated features.\n",
    "Example solution:\n",
    "\n",
    "- Find the two most correlated features (well you can read them from the plot above, but try find them yourself by)\n",
    "  - Mask diagonal points in the |correlation| matrix\n",
    "  - Unstack the dataframe into a pandas Series\n",
    "  - sort the values in decending order, then pick the top value (or use idxmax)\n",
    "- Make the scatter plot using the ax.scatter method.\n",
    "  - Make the distributions legible, either by setting the opacity (alpha=...).\n",
    "  - Label X axis, and Y axis including units.\n",
    "  - Include a legend two wine types.\n",
    "- Discuss the figure. Do you think using the both variables to distinguish wine quality is usefull?  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = red_corrolation.abs().unstack() < 1.0\n",
    "sorted_correlations = red_corrolation.unstack()[mask].abs().sort_values(ascending=False).drop_duplicates()\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1)\n",
    "features = sorted_correlations.index[:2]\n",
    "print(features)\n",
    "axes = [ax1, ax2]\n",
    "markers = [\"x\", \"x\"]\n",
    "\n",
    "for i, axis in enumerate(axes):\n",
    "    for j, t in enumerate([0, 1]):\n",
    "        mask = red[\"good_qual\"] == t\n",
    "        axis.scatter(red[features[i][0]], red[features[i][1]], label=t, marker=markers[j], s=0.5, alpha=0.5)\n",
    "        pass\n",
    "    # Draw legend\n",
    "    axis.legend()\n",
    "    axis.set_xlabel(features[i][0])\n",
    "    axis.set_ylabel(features[i][1])\n",
    "\n",
    "fig.suptitle(\"Highly correlated examples\")\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. Prepare a smaller pandas.DataFrame for visualisation and classification \n",
    "\n",
    "In the next sections, on decision trees and ensemble methods, we will try to classify the wine quality --- based on a subset of the available features. We also introduce labels for Poor and Good wines for plotting purposes:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define data and features\n",
    "features = ['fixed_acidity', 'volatile_acidity', 'citric_acid', 'residual_sugar',\n",
    "       'chlorides', 'free_sulfur_dioxide', 'total_sulfur_dioxide', 'density',\n",
    "       'pH', 'sulphates', 'alcohol']\n",
    "target   = ['good_qual']\n",
    "wtype = [\"Poor\",\"Good\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Therefore:\n",
    "\n",
    "* Create a pandas.DataFrame, called dataset, which contains only the desired features and the target variable;\n",
    "* Drop duplicates and NaN-values;\n",
    "* Shuffle the dataframe;\n",
    "* Create a pandas.DataFrame, called frames, containing the first 1000 observations of the dataset for each class\n",
    "* Create a sample dataset by doing the concat of frames\n",
    "* From sample panda dataframe convert into a numpy array for the inputs (called X) and target (called y);\n",
    "* Flatten the converted y array; and\n",
    "* Check their shapes to make sure they look alright.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset + remove duplicates and NAN\n",
    "dataset = red[features + target].drop_duplicates().dropna()\n",
    "\n",
    "# Define framge with shuffled 1000 samples or each type of quality\n",
    "frames_good_quality = dataset[ dataset[\"good_qual\"] == 1 ].sample(n=1000)\n",
    "frames_bad_quality = dataset[ dataset[\"good_qual\"] == 0 ].sample(n=1000)\n",
    "\n",
    "# Create sample dataset with shuffled data\n",
    "sample_dataset = pd.concat([frames_bad_quality, frames_good_quality])\n",
    "\n",
    "# From frames create sample inputs (x) and targets (y)\n",
    "x = np.asarray(sample_dataset[features])\n",
    "y = np.asarray(sample_dataset[target]).flatten()\n",
    "\n",
    "print(f\"Shape of x is {x.shape} \\nShape of y is {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision tree classification \n",
    "---\n",
    "This section covers 3 exercises on the use and understanding of decision trees and ensemble methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. Fit a decision tree classifier and plot the decision\n",
    "\n",
    "* Split dataset into training set and test set (x_train, x_test, y_train, y_test)\n",
    "* Create a `sklearn.tree.DecisionTreeClassifier` and set the maximum tree depth to 4, use `entropy` as the quality criterion.\n",
    "* Fit the decision tree classifier\n",
    "* Predict the response for the test and training datasets\n",
    "* Print the accuracy of test and training datasets\n",
    "* Make the decision tree graph and save it in png\n",
    "* Find the important feature in the decision tree (use feature_importances method in the decision tree). Why do you think this feature is of particular importance in distinguishing good and poor wines?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "from sklearn import metrics # Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import preprocessing # Import preprocessing for String-Int conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HYPER PARAMETERS\n",
    "MAX_DEPTH = 4\n",
    "\n",
    "# Split data int training and test dataset\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1)\n",
    "\n",
    "# Define basic decision tree object\n",
    "# ASK WHAT TO SET AS MIN_SAMPLE AND MIN_SAMPLE_LEAF\n",
    "decision_tree = DecisionTreeClassifier(criterion=\"entropy\", splitter=\"best\", max_depth=MAX_DEPTH)\n",
    "\n",
    "# Train the decition tree\n",
    "decision_tree.fit(x_train, y_train)\n",
    "\n",
    "# Create predicted data using the test dataset\n",
    "y_predicted_test = decision_tree.predict(x_test)\n",
    "y_predicted_train = decision_tree.predict(x_train)\n",
    "\n",
    "# Print accuracy of the model\n",
    "print(f\"Accuracy of basic decision tree w/ test dataset:\\t {metrics.accuracy_score(y_true=y_test, y_pred=y_predicted_test)}\")\n",
    "print(f\"Accuracy of basic decision tree w/ train dataset:\\t {metrics.accuracy_score(y_true=y_train, y_pred=y_predicted_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the decition tree as a png\n",
    "\n",
    "fig = plt.figure(figsize=(25,20))\n",
    "_ = tree.plot_tree(\n",
    "        decision_tree, \n",
    "        filled=True,\n",
    "        feature_names=features, \n",
    "        rounded=True, \n",
    "        class_names=wtype,\n",
    "    )\n",
    "\n",
    "fig.savefig(\"decision_tree.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the importance of each feature\n",
    "index_sort = np.argsort(decision_tree.feature_importances_)\n",
    "forest_importances = pd.Series(decision_tree.feature_importances_[index_sort], index=np.array(features)[index_sort])\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "forest_importances.plot.bar( ax=ax)\n",
    "ax.set_title(\"Feature importances\")\n",
    "ax.set_ylabel(\"Feature importance\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11. Fit a boosted decision tree classifier (1 Mark)\n",
    "\n",
    "\n",
    "* Create a `sklearn.tree.GradientBoostingClassifier` and set the maximum tree depth to 4 and n_estimators to 20.\n",
    "* Fit the boosted decision tree classifier\n",
    "* Predict the response and pring the accuracy for the test and train datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HYPER-PARAMETERS\n",
    "NUM_ESTIMATORS = 20\n",
    "MAX_DEPTH = 4\n",
    "LEARNING_RATE = 0.1\n",
    "LOSS_FUNCTION = \"log_loss\"\n",
    "\n",
    "# Define bvoosted decision tree object\n",
    "boosted_decision_tree = GradientBoostingClassifier(\n",
    "    loss=LOSS_FUNCTION,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    n_estimators=NUM_ESTIMATORS,\n",
    "    max_depth=MAX_DEPTH,\n",
    ")\n",
    "\n",
    "# Fit the boosted decision tree\n",
    "boosted_decision_tree.fit(x_train, y_train)\n",
    "\n",
    "# Compute predicted classes for boosted decision tree\n",
    "y_predicted_test = boosted_decision_tree.predict(x_test)\n",
    "y_predicted_train = boosted_decision_tree.predict(x_train)\n",
    "\n",
    "# Print accuracy of the model\n",
    "print(f\"Accuracy of basic decision tree w/ test dataset:\\t {metrics.accuracy_score(y_true=y_test, y_pred=y_predicted_test)}\")\n",
    "print(f\"Accuracy of basic decision tree w/ train dataset:\\t {metrics.accuracy_score(y_true=y_train, y_pred=y_predicted_train)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 12. Fit a Random forest decision tree classifier (1 Mark)\n",
    "\n",
    "* Use the splitted dataset defined in exercise 10.\n",
    "* Create a `sklearn.tree.RandomForestClassifier` and set the maximum tree depth to 4 and n_estimators to 100.\n",
    "* Use a low number of max features per tree, 3 to 5\n",
    "* Fit the random forest decision tree classifier\n",
    "* Predict the response for the test dataset\n",
    "* Print the accuracy\n",
    "* Discuss the results of the accuracy for the 3 methods (DT, BDT, RF). How could you improve on the results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HYPER-PARAMETERS\n",
    "NUM_ESTIMATORS = 100\n",
    "MAX_DEPTH = 3\n",
    "LEARNING_RATE = 0.1\n",
    "CRITERION = \"gini\"\n",
    "MAX_FEATURES = 5\n",
    "\n",
    "random_forest = RandomForestClassifier(\n",
    "    criterion=CRITERION,\n",
    "    n_estimators=NUM_ESTIMATORS,\n",
    "    max_depth=MAX_DEPTH,\n",
    "    max_features=MAX_FEATURES\n",
    ")\n",
    "\n",
    "# Fit the random forest\n",
    "random_forest.fit(x_train, y_train)\n",
    "\n",
    "# Compute predicted classes for random forest\n",
    "y_predicted_test = random_forest.predict(x_test)\n",
    "y_predicted_train = random_forest.predict(x_train)\n",
    "\n",
    "# Print accuracy of the model\n",
    "print(f\"Accuracy of basic decision tree w/ test dataset:\\t {metrics.accuracy_score(y_true=y_test, y_pred=y_predicted_test)}\")\n",
    "print(f\"Accuracy of basic decision tree w/ train dataset:\\t {metrics.accuracy_score(y_true=y_train, y_pred=y_predicted_train)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A**\n",
    "- BDT performed better than all on training sample, but shows sign of overtraining\n",
    "- RF performed marginally better than DT on testing sample, and has little overtraining\n",
    "- Performace needs to be tuned by doing a hyperparameter optimisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper parameter optimisation (bonus)\n",
    "\n",
    "We can use built in sklearn functionality to make the search of hyperparameters easier. We can use =GridSearchCV= though we will only introduce CrossValidation next week. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def plot_larning_rate_matrix(results, ada_dic):\n",
    "    # Desired: param_learning_rate, param_n_estimators, mean_test_score\n",
    "    scores = np.asarray(results[\"mean_test_score\"]).reshape(4,6)\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    im = ax.imshow(scores, cmap=\"gray\")\n",
    "    ax.set(\n",
    "        xticks=np.arange(0,6),\n",
    "        yticks=np.arange(0,4), \n",
    "        yticklabels=ada_dic[\"learning_rate\"],\n",
    "        xticklabels=ada_dic[\"n_estimators\"]\n",
    "    )\n",
    "    ax.set_title(\"Learning rate matrix\")\n",
    "    ax.set_xlabel(\"learning rate\")\n",
    "    ax.set_ylabel(\"number of estimatiors\")\n",
    "    for i in range(4):\n",
    "        for j in range(6):\n",
    "            text = ax.text(\n",
    "                j, i, \n",
    "                f\"{scores[i, j]:.2f}\",\n",
    "                ha=\"center\", \n",
    "                va=\"center\", \n",
    "                color=\"b\"\n",
    "            )\n",
    "\n",
    "    fig.colorbar(im)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the following dictionary to run a scan over AdaBoostClassifer. Note that `n_jobs` can be used to employ multiple CPUs on your PC.\n",
    "\n",
    "Get the best fit parameters from your search. Hint: check the methods attached to the search object. `best_estimator_` is particularly useful for this.\n",
    "\n",
    "Calculate the accuracy as above.\n",
    "\n",
    "Try other algorithms (GradBoosting, RandomForests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_dic={\n",
    "    \"n_estimators\":[10,50,100,200,500,1000],\n",
    "    \"learning_rate\": [.05,.1,.5,1],\n",
    "    }\n",
    "\n",
    "# Define random forest object\n",
    "ada_classifier = AdaBoostClassifier()\n",
    "\n",
    "grid = GridSearchCV(ada_classifier, ada_dic, n_jobs=5)\n",
    "grid.fit(x_train, y_train)\n",
    "\n",
    "print(f\"The best score is \\t{grid.best_score_}\")\n",
    "print(f\"The best parameters are \\t{grid.best_params_}\")\n",
    "\n",
    "results = pd.DataFrame.from_dict(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot matrix of scores for each combination of hyperparameters\n",
    "plot_larning_rate_matrix(results, ada_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
