{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report 1: Parameter estimation using Monte Carlo simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.integrate import quad\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from iminuit import Minuit\n",
    "import random\n",
    "import timeit\n",
    "import math\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of probability distribution\n",
    "\n",
    "In this report, we will be analysing a decay process X -> D which can be caractarised by the folowing probaboility distribution:\n",
    "\\begin{equation}\n",
    "P(t;\\tau, \\Delta m_s, V) \\;\\; \\alpha \\;\\; (1 + Vsin(\\Delta mt)) \\cdot e^{-t/\\tau}\n",
    "\\end{equation}\n",
    "\n",
    "We note that the above equation is only proportionate and is unormalised. In order to make the above equation a PDF we would need to add a normalisation factior, $t_{norm}$.\n",
    "\n",
    "In this section of the report, we will create a lambda function to analise the functional form of the drobability distribution in order to help us later on in the analysis.\n",
    "\n",
    "We are told to look at this distribution within the bounds of $t \\in [0, 10]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lambda function of pdf\n",
    "distribution = lambda t, tau, delta_mass, V : (1 + V*np.sin(delta_mass*t))*np.exp(-t/tau)\n",
    "\n",
    "# We define function bounds and time values\n",
    "X_BOUNDS = (0, 10)\n",
    "\n",
    "# Define the time values\n",
    "n_steps = 1000                           # For now we will plot 100 points within the bounds\n",
    "t = np.linspace(*X_BOUNDS, n_steps, endpoint=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we compute values of the distribution using any set of parameters, we can compute the integral of the function between the bounds we will be investigating. This will allow us to noramlise the functiuon later in the report when we generate random points and fit the function.\n",
    "\n",
    "We will evaluete the integral between the bounds of $t \\in [0, 10]$ using numerical integration. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now pick different sets of parameters ot investigate how they afect the functional form of the distribution. From looking at the equation, we can expect the function to take a decaying sinusoidal form with $\\tau$ being the decay constant, V be the amplitude of the harmonic component and $\\Delta m_s$ to be the angular frequency of the harmonic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a lambda fuinction to compute the integral of the function using a specific set of parameters\n",
    "normalisation_factor = lambda parameters, bounds : quad(distribution, *bounds, args=parameters, limit=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choosing different parameters (tau, delta_mass, Potential)\n",
    "parameters_1 = (1.5, 20, 0.1)\n",
    "parameters_2 = (2.0, 5.0, 1.0)\n",
    "parameters_3 = (1.0, 5.0, 3.0)\n",
    "\n",
    "# We plot the function for these parameters\n",
    "plt.plot(t, distribution(t, *parameters_1), label=\"Parameters 1\", ls=\"--\")\n",
    "plt.plot(t, distribution(t, *parameters_2), label=\"Parameters 2\", ls=\"-.\")\n",
    "plt.plot(t, distribution(t, *parameters_3), label=\"Parameters 3\", ls=\"-\")\n",
    "plt.xlabel(\"time, t (arbitrary units)\")\n",
    "plt.ylabel(r\"P*$t_{norm}$ (arbitrary units)\")\n",
    "plt.title(\"Functional form of decay time\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need to create an algorithm to randomly draw a value within this distribution. There are multiple methods for us to do so.\n",
    "\n",
    "Let us try to use the box method for a start. We note that in this case as the minimum value of the distribution is not zero, We will need to identify the max and min point of the distriution in order for us to define the box around the distribution.\n",
    "\n",
    "We will test our function by trying to find the maximum and minimum point of the function using parameters_1, which from the plot we expect a y_max of ~ 3.0 and y_min of ~ -0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find max point of the distribution\n",
    "def find_max(function, bound_low, bound_high, parameters=parameters_3, grid=100000,):\n",
    "    \"\"\"\n",
    "    Return the maximum value of a function\n",
    "    \"\"\"\n",
    "    # Note that grid defines the number of steps within thedefined range\n",
    "    if (not grid >= 0):\n",
    "        raise ValueError(\"Grid must be a a positive intiger\")\n",
    "    # Generate grid of x values\n",
    "    x = np.linspace(bound_low, bound_high, num=grid, endpoint=True,)\n",
    "    # Compute and return the maximum point of function\n",
    "    y = function(x, *parameters)\n",
    "    return x[y.argmax()], y.max()\n",
    "\n",
    "# Function to find min point of the distribution\n",
    "def find_min(function, bound_low, bound_high, parameters=parameters_3, grid=100000,):\n",
    "    \"\"\"\n",
    "    Return the minimum value of a function\n",
    "    \"\"\"\n",
    "    # Note that grid defines the number of steps within thedefined range\n",
    "    if (not grid >= 0):\n",
    "        raise ValueError(\"Grid must be a a positive intiger\")\n",
    "    # Generate grid of x values\n",
    "    x = np.linspace(bound_low, bound_high, num=grid, endpoint=True,)\n",
    "    # Compute and return the minimum point of function\n",
    "    y = function(x, *parameters)\n",
    "    return x[y.argmin()], y.min()\n",
    "\n",
    "x_peak_max, y_max = find_max(distribution, *X_BOUNDS)\n",
    "x_peak_min, y_min = find_min(distribution, *X_BOUNDS)\n",
    "Y_BOUNDS = (y_min, y_max)\n",
    "\n",
    "print(f\"Maximum point of distribution with parameters_1 is {y_max:.3f}\")\n",
    "print(f\"Minimum point of distribution with parameters_1 is {y_min:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have obtained the maximum and minimum points, we will attempt to implement an algoritm to randomly draw values within this distribution using the box method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_method(func, x_min, x_max, y_min, y_max):\n",
    "    while True:\n",
    "        x = np.random.uniform(x_min, x_max)\n",
    "        y_function = func(x, *parameters_3)\n",
    "        y_box = np.random.uniform(y_min, y_max)\n",
    "        if y_box <= y_function:\n",
    "            return (x, y_box)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now generate 5000 random points and check they are within the bounds of the distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_points_x = []\n",
    "random_points_y = []\n",
    "n_random_points = 5000\n",
    "\n",
    "# Generate 5000 points\n",
    "for _ in range(n_random_points):\n",
    "    x, y = box_method(distribution, *X_BOUNDS, *Y_BOUNDS)\n",
    "    random_points_x.append(x)\n",
    "    random_points_y.append(y)\n",
    "\n",
    "# Plot function and points\n",
    "plt.plot(t, distribution(t, *parameters_3), label=\"True distribution\", c=\"red\")\n",
    "plt.scatter(random_points_x, random_points_y, s=0.7, marker=\"x\", c=\"g\", label=\"Box Method\")\n",
    "plt.axhline(0, xmin=X_BOUNDS[0], xmax=X_BOUNDS[1], linestyle=\"--\", c=\"black\", linewidth=1)\n",
    "plt.axhline(y_min, xmin=X_BOUNDS[0], xmax=X_BOUNDS[1], linestyle=\"-.\", c=\"black\", linewidth=1.5, label=\"Box\")\n",
    "plt.axhline(y_max, xmin=X_BOUNDS[0], xmax=X_BOUNDS[1], linestyle=\"-.\", c=\"black\", linewidth=1.5,)\n",
    "plt.axvline(X_BOUNDS[0], ymin=y_min, ymax=y_max, linestyle=\"-.\", c=\"black\", linewidth=1.5,)\n",
    "plt.axvline(X_BOUNDS[1], ymin=y_min, ymax=y_max, linestyle=\"-.\", c=\"black\", linewidth=1.5,)\n",
    "plt.xlabel(\"time, t (arbitrary units)\")\n",
    "plt.ylabel(r\"P*$t_{norm}$ (arbitrary units)\")\n",
    "plt.title(\"Random value generation according to decay distribution\")\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that we are getting random points being drawn below the function line. But this is not what is required. We require the random points to be drawn from the area bounded between the function line and the x axis. As a result, to fix this, we must discriminate random points where $y_{func}$ is above and below the x axis. Fow points where $y_{func}$ is negative, we accept $y_{box}$ if it is greater than $y_{func}$.\n",
    "\n",
    "We write the fixed function below and re-generate 5000 random points ot see if it is working:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_method_fixed(func, x_min, x_max, y_min, y_max):\n",
    "    while True:\n",
    "        x = np.random.uniform(x_min, x_max)\n",
    "        y_function = func(x, *parameters_3)\n",
    "        y_box = np.random.uniform(y_min, y_max)\n",
    "        # Accept condition if y_function is above x axis\n",
    "        if (y_function >= 0.0) and (y_box>= 0.0) and (y_box <= y_function):\n",
    "            return (x, y_box)\n",
    "        # Accept condition if y_function is below x axis\n",
    "        if (y_function <= 0.0) and (y_box <= 0) and (y_box >= y_function):\n",
    "            return (x, y_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_points_x = []\n",
    "random_points_y = []\n",
    "n_random_points = 5000\n",
    "\n",
    "# Generate 5000 points\n",
    "for _ in range(n_random_points):\n",
    "    x, y = box_method_fixed(distribution, *X_BOUNDS, *Y_BOUNDS)\n",
    "    random_points_x.append(x)\n",
    "    random_points_y.append(y)\n",
    "\n",
    "# Plot function and points\n",
    "plt.plot(t, distribution(t, *parameters_3), label=\"True distribution\", c=\"red\")\n",
    "plt.scatter(random_points_x, random_points_y, s=0.7, marker=\"x\", c=\"g\", label=\"Random Point\")\n",
    "plt.axhline(0, xmin=X_BOUNDS[0], xmax=X_BOUNDS[1], linestyle=\"--\", c=\"black\", linewidth=1)\n",
    "plt.axhline(y_min, xmin=X_BOUNDS[0], xmax=X_BOUNDS[1], linestyle=\"-.\", c=\"black\", linewidth=1.5, label=\"Box\")\n",
    "plt.axhline(y_max, xmin=X_BOUNDS[0], xmax=X_BOUNDS[1], linestyle=\"-.\", c=\"black\", linewidth=1.5,)\n",
    "plt.axvline(X_BOUNDS[0], ymin=y_min, ymax=y_max, linestyle=\"-.\", c=\"black\", linewidth=1.5,)\n",
    "plt.axvline(X_BOUNDS[1], ymin=y_min, ymax=y_max, linestyle=\"-.\", c=\"black\", linewidth=1.5,)\n",
    "plt.xlabel(\"time, t (arbitrary units)\")\n",
    "plt.ylabel(r\"P*$t_{norm}$ (arbitrary units)\")\n",
    "plt.title(\"Random value generation according to decay distribution\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a function capable of generating random points, we can look to optimise it in order to speed up the MC simulation. \n",
    "\n",
    "For now we will keep using the box method (although it is not the most optimal) and will look to shave time another way. It is known that when using in built python types, It is quicker to python libraries rather than numpy where possible. Hence we will replace the lambda function and the box method algorith to use the math and random packages instead and compare the computation times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rewrite the lambda function to use the python math function\n",
    "distribution_optimised = lambda t, tau, delta_mass, V : (1 + V*math.sin(delta_mass*t))*math.exp(-t/tau)\n",
    "\n",
    "# Rewrite the box method algoritm to use the new function and to use random library\n",
    "def box_method_optimised(func, x_min, x_max, y_min, y_max):\n",
    "    while True:\n",
    "        x = random.uniform(x_min, x_max)\n",
    "        y_function = func(x, *parameters_3)\n",
    "        y_box = random.uniform(y_min, y_max)\n",
    "        # Accept condition if y_function is above x axis\n",
    "        if (y_function >= 0.0) and (y_box>= 0.0) and (y_box <= y_function):\n",
    "            return (x, y_box)\n",
    "        # Accept condition if y_function is below x axis\n",
    "        if (y_function <= 0.0) and (y_box <= 0) and (y_box >= y_function):\n",
    "            return (x, y_box)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the timeit function, we can now look at different combinations to see how the average function time takes.\n",
    "\n",
    "The three combinations we will look at is:\n",
    "* Function w/ Numpy + Random generator w/ Numpy\n",
    "* Function w/ Math + Random generator w/ Numpy\n",
    "* Function w/ Numpy + Random generator w/ Math\n",
    "* Function w/ Math + Random generator w/ Math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\ntimeit resuts for: Function w/ Numpy + Random generator w/ Numpy\")\n",
    "%timeit box_method_fixed(distribution, *X_BOUNDS, *Y_BOUNDS)\n",
    "\n",
    "print(\"\\ntimeit resuts for: Function w/ Math + Random generator w/ Numpy\")\n",
    "%timeit box_method_fixed(distribution_optimised, *X_BOUNDS, *Y_BOUNDS)\n",
    "\n",
    "print(\"\\ntimeit resuts for: Function w/ Numpy + Random generator w/ Math\")\n",
    "%timeit box_method_optimised(distribution, *X_BOUNDS, *Y_BOUNDS)\n",
    "\n",
    "print(\"\\ntimeit resuts for: Function w/ Math + Random generator w/ Math\")\n",
    "%timeit box_method_optimised(distribution_optimised, *X_BOUNDS, *Y_BOUNDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, by switching to both a box method algorithm and function that use python's standard libraries, we have optimised our MC simulation ~ 6 fold (~80% increase). This will provide a noticable difference when we are generating large datasets.\n",
    "\n",
    "The previous method assumed that the function could take negative values. If we assume the oppposite (ie the range of V is $\\in [0, 1]$), we can take afurther step to optimisation by changing the shape of the area where we draw our random values from a box to a triangle. We will pick the peak of the triangle to be the located at the point t = 0 and the triangle will have a hight corresponding to the highest point in the distribution. This will ensure we have an area that compleatly encompases our distribution given the previous assumptions.\n",
    "\n",
    "Below we visualise the traingle compared to the box used previously. From now on we will be using values for the parameter V within $\\in [0, 1]$.\n",
    "\n",
    "The slope of the line defining the triangle is given by $m = -\\frac{y_{max}}{x_max}$ and the y intercept is given by $y_{max}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variables for visualisation\n",
    "parameters_4 = (1.5, 20.0, 0.1)\n",
    "x_peak_max, y_max = find_max(distribution, *X_BOUNDS, parameters=parameters_4)\n",
    "x_peak_mim, y_min = find_min(distribution, *X_BOUNDS, parameters=parameters_4)\n",
    "Y_BOUNDS = (y_min, y_max)\n",
    "\n",
    "# Visualisation of bounding box vs bounding triangle\n",
    "# Plot distribution\n",
    "plt.plot(t, distribution(t, *parameters_4), label=\"True distribution\", c=\"red\")\n",
    "# Plot bounding box\n",
    "plt.axhline(0.0, xmin=X_BOUNDS[0], xmax=X_BOUNDS[1], linestyle=\"-.\", c=\"black\", linewidth=1.5, label=\"Box\")\n",
    "plt.axhline(y_max, xmin=X_BOUNDS[0], xmax=X_BOUNDS[1], linestyle=\"-.\", c=\"black\", linewidth=1.5,)\n",
    "plt.axvline(X_BOUNDS[0], ymin=y_min, ymax=y_max, linestyle=\"-.\", c=\"black\", linewidth=1.5,)\n",
    "plt.axvline(X_BOUNDS[1], ymin=y_min, ymax=y_max, linestyle=\"-.\", c=\"black\", linewidth=1.5,)\n",
    "# Plot bounding triangle\n",
    "plt.plot(t, -(y_max/X_BOUNDS[1])*t+y_max, label=\"Triangle\", c=\"blue\", linewidth=1.5, linestyle=\"-.\")\n",
    "\n",
    "plt.xlabel(\"time, t (arbitrary units)\")\n",
    "plt.ylabel(r\"P*$t_{norm}$ (arbitrary units)\")\n",
    "plt.title(\"Triangle vs Box bounding areas for random number generation\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, we have imediately cut a significant region of the box which would not have contributed to accepted random values. We should however note that this triangle method only works when $\\tau$ is < ~2.6 a.u. This is because above 2.6 the distribution will start to xlip outside the box, resulting in a section of the distribution for which random numbers are not being generated.\n",
    "\n",
    "Hence for the triangle we name two assumptions:\n",
    "* $\\tau$ is < 2.6 a.u\n",
    "* V is within the bounds of [0, 1]\n",
    "\n",
    "The nominal values for the parameters given to us fit these assumptions, hence we will build a triangle random number generatr and compare how quicker it is compared ot the box method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rewrite the box method algoritm to use a triangular bounding box\n",
    "# Using assumption that all values of distribution are >= 0, we can drop out checks for values below 0\n",
    "def triangle_method(func, x_min, x_max, y_min, y_max):\n",
    "    while True:\n",
    "        x = y_max*random.triangular(x_min, x_max, x_min)\n",
    "        y_function = func(x, *parameters_4)\n",
    "        y_triangle =x_max*random.uniform(y_min, y_max,)\n",
    "        # Accept condition if y_function is above x axis\n",
    "        if (y_triangle <= y_function):\n",
    "            return (x, y_triangle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now use this random value generator to generate random points and visualise them to assure that they are within our distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_points_x = []\n",
    "random_points_y = []\n",
    "n_random_points = 10000\n",
    "\n",
    "# Generate 5000 points\n",
    "for _ in range(n_random_points):\n",
    "    x, y = triangle_method(distribution, x_min=X_BOUNDS[0], x_max=X_BOUNDS[1], y_min=y_min, y_max=y_max)\n",
    "    random_points_x.append(x)\n",
    "    random_points_y.append(y)\n",
    "\n",
    "# Plot function and points\n",
    "plt.plot(t, distribution(t, *parameters_4), label=\"True distribution\", c=\"red\")\n",
    "plt.scatter(random_points_x, random_points_y, s=0.7, marker=\"x\", c=\"g\", label=\"Random Point\")\n",
    "plt.xlabel(\"time, t (arbitrary units)\")\n",
    "plt.ylabel(r\"P*$t_{norm}$ (arbitrary units)\")\n",
    "plt.title(\"Random value generation according to decay distribution (triangle)\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now compare this method of generation with the unoptimised and optimised box method with timeit to see the imporvement in generation time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\ntimeit resuts for: Unoptimsed box method\")\n",
    "%timeit box_method_fixed(distribution, *X_BOUNDS, *Y_BOUNDS)\n",
    "\n",
    "print(\"\\ntimeit resuts for: Optimised box method\")\n",
    "%timeit box_method_optimised(distribution_optimised, *X_BOUNDS, *Y_BOUNDS)\n",
    "\n",
    "print(\"\\ntimeit resuts for: Triangle method\")\n",
    "%timeit triangle_method(distribution_optimised, *X_BOUNDS, *Y_BOUNDS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our Improvements compared to the unoptimised vs optimised box method is ~10 fold, however we note that the triangle method, which should have yeilded even more optimised preformance, seems ro be on-par with the unoptimised box method. Perhapse this is a result of the two triangular distributions resulting on more random points being called before a random point gets accepted.\n",
    "\n",
    "Irrespective, we will use the optimied box method throughout the rest of the report due to it having the quickest function run time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now create a class called ProbabilityDensityFunction which contains class methods and members to be shared for all probability density classes.\n",
    "We also create a child class called HarmonicWithDecay which inherits ProbabilityDensityFunction and contain methods to generate random points in a distribution of this form and set different parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProbabilityDensityFunction(object):\n",
    "    \"\"\"\n",
    "    Parent class containing common methods and members to be used by all pdf classes\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, bounds):\n",
    "\n",
    "        if (not isinstance(bounds, tuple)):\n",
    "            raise TypeError(\"Variable bound must be a tuple with the form (boundMin, boundMax)\")\n",
    "        if (not len(bounds) == 2):\n",
    "            raise ValueError(\"Variable bound must have form (boundMin, boundMax)\")\n",
    "        if (not bounds[0] < bounds[1]):\n",
    "            raise ValueError(\"First element in tuple must be smaller than second\")\n",
    "        \n",
    "        # Initialise class variables\n",
    "        self.boundMin, self.boundMax = bounds\n",
    "\n",
    "        # Initialise array to contain generated events\n",
    "        self.mass = []\n",
    "\n",
    "    def integrate(self, limits):\n",
    "        \"\"\"\n",
    "        Evaluate the integral of the pdf within the specified bounds\n",
    "        ##### NOTE: Integral is not normalised within the specified bounds of the class #####\n",
    "        \"\"\"\n",
    "\n",
    "        if (not isinstance(limits, tuple)):\n",
    "            raise TypeError(\"Variable bound must be a tuple with the form (limitMin, limitMax)\")\n",
    "        if (not len(limits) == 2):\n",
    "            raise ValueError(\"Variable bound must have form (limitMin, limitMax)\")\n",
    "        if (not limits[0] < limits[1]):\n",
    "            raise ValueError(\"First element in tuple must be smaller than second\")\n",
    "        if (not limits[0] >= self.boundMin):\n",
    "            raise ValueError(\"Lower integral limit must be larger than lower bound of pdf\")\n",
    "        if (not limits[1] <= self.boundMax):\n",
    "            raise ValueError(\"Higher integral limit must be smaller than upper bound of pdf\")\n",
    "    \n",
    "        limitLow, limitHigh = limits\n",
    "        integralResult, IntegralError = quad(self.evaluate, limitLow, limitHigh, limit=150) \n",
    "        return integralResult\n",
    "\n",
    "    def getMass(self, flush=False):\n",
    "        \"\"\"\n",
    "        Return numpy array containing all generated values.\n",
    "        If flush is set to true, the masses of the class will be deleted once returned.\n",
    "        \"\"\"\n",
    "        mass = np.array(self.mass)\n",
    "        # flush masses if desired\n",
    "        if flush:\n",
    "            self.flushMass()\n",
    "\n",
    "        return mass\n",
    "    \n",
    "\n",
    "    def flushMass(self,):\n",
    "        \"\"\"\n",
    "        Empty the list containing the generated masses\n",
    "        \"\"\"\n",
    "\n",
    "        self.mass.clear()\n",
    "\n",
    "class HarmonicWithDecay(ProbabilityDensityFunction):\n",
    "    \"\"\"\n",
    "    Class that will generate a random value according to a harminic signal with exponential decay\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, tau, deltaMass, V, bounds):\n",
    "\n",
    "        if (not isinstance(bounds, tuple)):\n",
    "            raise TypeError(\"Variable bound must be a tuple with the form (boundMin, boundMax)\")\n",
    "        if (not len(bounds) == 2):\n",
    "            raise ValueError(\"Variable bound must have form (boundMin, boundMax)\")\n",
    "        if (not bounds[0] < bounds[1]):\n",
    "            raise ValueError(\"First element in tuple must be smaller than second\")\n",
    "\n",
    "        # Initialise parent class\n",
    "        super().__init__(bounds)\n",
    "\n",
    "        # Initialise class variables\n",
    "        self.boundMin, self.boundMax = bounds\n",
    "        self.tau = tau\n",
    "        self.deltaMass = deltaMass\n",
    "        self.V = V \n",
    "\n",
    "        # Find maximum and minimum values of the distribution within the bounds\n",
    "        self.maxValue = self._findMax()\n",
    "        self.minValue = self._findMin()\n",
    "\n",
    "        # Define normalisation factor using parameters passed to constructor\n",
    "        self.getNormalisationFactor() \n",
    "\n",
    "    def _findMax(self, grid=100000,):\n",
    "        \"\"\"\n",
    "        Return the maximum value of a function\n",
    "        \"\"\"\n",
    "        # Note that grid defines the number of steps within thedefined range\n",
    "        if (not grid >= 0):\n",
    "            raise ValueError(\"Grid must be a a positive intiger\")\n",
    "        # Generate grid of x values\n",
    "        x = np.linspace(self.boundMin, self.boundMax, num=grid, endpoint=True,)\n",
    "        # Compute and return the maximum point of function\n",
    "        y = self.evaluate(x)\n",
    "        return y.max()\n",
    "\n",
    "    def _findMin(self,grid=100000,):\n",
    "        \"\"\"\n",
    "        Return the minimum value of a function\n",
    "        \"\"\"\n",
    "        # Note that grid defines the number of steps within thedefined range\n",
    "        if (not grid >= 0):\n",
    "            raise ValueError(\"Grid must be a a positive intiger\")\n",
    "        # Generate grid of x values\n",
    "        x = np.linspace(self.boundMin, self.boundMax, num=grid, endpoint=True,)\n",
    "        # Compute and return the minimum point of function\n",
    "        y = self.evaluate(x)\n",
    "        return y.min()\n",
    "\n",
    "    def evaluate(self, t,):\n",
    "        \"\"\"\n",
    "        Evaluate the function of the distribution\n",
    "        Note: returns unormalised values \n",
    "        \"\"\"\n",
    "        \n",
    "        return (1 + self.V*np.sin(self.deltaMass*t))*np.exp(-t/self.tau) \n",
    "\n",
    "    def _evaluateOptimised(self, t):\n",
    "        \"\"\"\n",
    "        Evatuate the function of the distribution when the t value passed is not a numpy array.\n",
    "        Optimised for operations using python's fundamental types. This method is used in this class when generating\n",
    "        random points from the distribution\n",
    "        NOTE: Returns un-normalised values\n",
    "        \"\"\"\n",
    "\n",
    "        return (1 + self.V*math.sin(self.deltaMass*t))*math.exp(-t/self.tau)\n",
    "\n",
    "    def next(self,):\n",
    "        \"\"\"\n",
    "        Generate a single random variable according to the class' distribution using the box method.\n",
    "        Will return and append generated variable to mass list.\n",
    "        \"\"\"\n",
    "        # Compute the normalisation value numerically for the Harmonic with decay class\n",
    "        while True:\n",
    "            x = random.uniform(self.boundMin, self.boundMax)\n",
    "            y_function = self._evaluateOptimised(x,)\n",
    "            y_box = random.uniform(0, self.maxValue, )\n",
    "            # Accept condition if y_function is above x axis\n",
    "            if (y_box <= y_function):\n",
    "                self.mass.append(x)\n",
    "                return (x, y_box)\n",
    "            \n",
    "    def getNormalisationFactor(self,):\n",
    "        \"\"\"\n",
    "        Update the normalisation factor to be consistant with any updated parameters of the class.\n",
    "        \"\"\"\n",
    "\n",
    "        # Compute and update class member\n",
    "        self.normalisationFactor = self.integrate((self.boundMin, self.boundMax))\n",
    "        \n",
    "    def setParameters(self, tau=None, deltaMass=None, V=None):\n",
    "        \"\"\"\n",
    "        Set passed variables as parameters for pdf\n",
    "        \"\"\"\n",
    "\n",
    "        # Use default values for parameters of none are passed through kwargs\n",
    "        if not tau == None:                     self.tau = tau\n",
    "        if not deltaMass == None:               self.deltaMass = deltaMass       \n",
    "        if not V == None:                       self.V = V   \n",
    "\n",
    "        # Update normalisation factor for the new parameters\n",
    "        self.getNormalisationFactor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will test the class by trying to recreate the plot using the nominal set of parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = HarmonicWithDecay(tau=1.5, deltaMass=20.0, V=0.1, bounds=X_BOUNDS)\n",
    "\n",
    "random_points_x = []\n",
    "random_points_y = []\n",
    "n_random_points = 5000\n",
    "\n",
    "# Generate 5000 points\n",
    "for _ in range(n_random_points):\n",
    "    x, y = pdf.next()\n",
    "    random_points_x.append(x)\n",
    "    random_points_y.append(y)\n",
    "\n",
    "# Plot function and points\n",
    "plt.plot(t, pdf.evaluate(t,) , label=\"True distribution\", c=\"red\") \n",
    "plt.scatter(random_points_x, random_points_y, s=0.7, marker=\"x\", c=\"g\", label=\"Triangle Method\")\n",
    "plt.axhline(0, xmin=X_BOUNDS[0], xmax=X_BOUNDS[1], linestyle=\"--\", c=\"black\", linewidth=1)\n",
    "plt.xlabel(\"time, t (arbitrary units)\")\n",
    "plt.ylabel(r\"P*$t_{norm}$ (arbitrary units)\")\n",
    "plt.title(\"Random value generation according to decay distribution\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the plot, We have succesfully created a class which can generate points from the decay distribution.\n",
    "\n",
    "We will now generate a toy dataset of times drawn from the harmonic w/ exponential decay distribution using our new class.\n",
    "For this we will use the nominal parameter values provided. We can then plot a histogram with out toy dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define nominal parameter values\n",
    "nominal_tau = 1.5\n",
    "nominal_delta_mass = 20.0\n",
    "nominal_V = 0.1\n",
    "\n",
    "# Define number of events to be generated\n",
    "n_events = 10000\n",
    "\n",
    "# Prodice instance of class using nominal values\n",
    "nominal_pdf = HarmonicWithDecay(tau=nominal_tau, deltaMass=nominal_delta_mass, V=nominal_V, bounds=X_BOUNDS)\n",
    "\n",
    "# Generate 1000 events and store them\n",
    "for _ in range(n_events):\n",
    "    nominal_pdf.next()\n",
    "# Return masses and delete them in the clas s.t the class can be reused for a new toy experiment\n",
    "events = nominal_pdf.getMass(flush=True)\n",
    "# Plot Histogram of toy dataset\n",
    "_ = plt.hist(events, bins=200, histtype=\"step\") \n",
    "plt.xlabel(\"time, t (arbitrary units)\")\n",
    "plt.ylabel(r\"Frequency of events (counts)\")\n",
    "plt.title(\"Histogram of toy dataset using nominal value of parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now look to use a maximum likelyhood fit to determine the precision of the each parameters of the distribution. To do so, we will need to fit 100 toy datasets. Before we do so, We will write a class which will contain the maximum likelihood statistic which will be used to minimise out fit. We will also look to fit the above toy dataset with iminuit in order to verify that we are indeed fitting the dataset correctly.\n",
    "\n",
    "Below we write the maximum likelyhood class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NegativeLogLikelihood(object):\n",
    "    \"\"\"\n",
    "    Class containing minimisation statistic to be for pdf fitting. The class takes in events as the input.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, pdf, data):\n",
    "\n",
    "        self.pdf = pdf\n",
    "        self.data = data\n",
    "\n",
    "    def setData(self, data):\n",
    "        \"\"\"\n",
    "        Assign data class member to new dataset for the reuse of this class\n",
    "        \"\"\"\n",
    "        \n",
    "        self.data = data\n",
    "\n",
    "    def findNormalisationFactor(self,):\n",
    "        \"\"\"\n",
    "        Find integral of pdf \n",
    "        \"\"\"\n",
    "        \n",
    "        # Define integration limits\n",
    "        normalisationLimits = (self.pdf.boundMin, self.pdf.boundMax)\n",
    "\n",
    "        return self.pdf.integrate(normalisationLimits)\n",
    "    \n",
    "    def evaluate(self, tau, deltaMass, V):\n",
    "        \"\"\"\n",
    "        Evaluate negative log likelihood statisctic for passed parameters\n",
    "        \"\"\"\n",
    "\n",
    "        # set new parameters\n",
    "        self.pdf.setParameters(tau=tau, deltaMass=deltaMass, V=V)\n",
    "\n",
    "        # compute likelyhood using passed parameters\n",
    "        normalisation = self.pdf.integrate((self.pdf.boundMin, self.pdf.boundMax))\n",
    "        likelihood = self.pdf.evaluate(self.data,) / normalisation\n",
    "        # set any negative likelihoods to neglegable positive values\n",
    "        if (likelihood <= 0).any():\n",
    "            likelihood[likelihood <=0 ] = 1e-10\n",
    "        loglikelihood = np.log(likelihood)\n",
    "        return -loglikelihood.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use iminuit to make a quick fit of our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary containing the name of the parameters and our initial guesses\n",
    "initial_parameters = {\n",
    "    \"tau\"       : 1.5,\n",
    "    \"deltaMass\" : 20.0,\n",
    "    \"V\"         : 0.1\n",
    "}\n",
    "\n",
    "# Initialise the statistic object\n",
    "negative_log_likelihood = NegativeLogLikelihood(nominal_pdf, events)\n",
    "# Initialise minimiser object\n",
    "minimiser = Minuit(negative_log_likelihood.evaluate, **initial_parameters,)\n",
    "# Limit the range of possible values parameters to sensible values given the assumptions mentioned above\n",
    "# minimiser.limits = [(0.7, 2.0), (20.0, 38.0), (0.03, 0.2)]\n",
    "minimiser.errordef = 0.5\n",
    "# Minimise the fit \n",
    "results = minimiser.migrad()\n",
    "# View results\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the minimised parameters are indeed pretty close to the nominal values used to generate the dataset. Evidently, they are not perferect as they are more than 1 standard deviation form the true values, but given that the dataset is comprised of only 1000 events, that is understandable. Were we to generate more events we would see a more accurate fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the minimised values of the parameters to plot  fitted distribution ontop of the dataset to see how good the fit performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given that out nominal_pdf object currently has its parameters set to the optimised parameters, we don't have to set them\n",
    "plt.plot(t, nominal_pdf.evaluate(t)/nominal_pdf.integrate(X_BOUNDS), c=\"purple\", ls=\"-\", label=\"Fitted curve\")\n",
    "_ = plt.hist(events, bins=200, histtype=\"step\", label=\"Toy dataset\", color=\"blue\", density=True) \n",
    "plt.xlabel(\"time, t (arbitrary units)\")\n",
    "plt.ylabel(r\"Probability\")\n",
    "plt.title(\"Normalised toy dataset distribution with fits\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we see tha we are able to create an accurate fit of the toy dataset, We will create a function to generate 100 toy datasets and fit each one. The function would then store the optimised parameters s.t we can plot the distribution of optimised parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimised_values(results, parameter_keys):  \n",
    "    \"\"\"\n",
    "    A function that will return a list of the values of the parameters stored in a migrad results table\n",
    "    \"\"\"\n",
    "    parameter_values = []\n",
    "    # Iterate over all keys\n",
    "    for key in parameter_keys:\n",
    "        parameter_values.append(results.params[key].value)\n",
    "    return parameter_values    \n",
    "\n",
    "# Function that will create and fit one toy dataset\n",
    "def generate_and_fit_dataset(\n",
    "        bounds,\n",
    "        truth_parameters,\n",
    "        n_events=10000,\n",
    "):\n",
    "    \"\"\"\n",
    "    Function will generate and fit one toy dataset. The structure of the parameter lists are [tau, delta mass, V]\n",
    "    Returns list of paramer values in the same order as the initial parameter dictionary (and input parameter list)\n",
    "    \"\"\"\n",
    "    # Define initial parameter dictionary\n",
    "    initial_parameters = {\n",
    "        \"tau\"       : 1.6,\n",
    "        \"deltaMass\" : 20.5,\n",
    "        \"V\"         : 0.11\n",
    "    }\n",
    "    # Generate pdf object\n",
    "    pdf = HarmonicWithDecay(*truth_parameters.values(), bounds)\n",
    "    # Generate Events\n",
    "    for _ in range(n_events):\n",
    "        pdf.next()\n",
    "    events = pdf.getMass(flush=True)\n",
    "\n",
    "    # Minimise the events\n",
    "    negative_log_likelihood = NegativeLogLikelihood(nominal_pdf, events)\n",
    "    minimiser = Minuit(negative_log_likelihood.evaluate, **initial_parameters)\n",
    "    # Limit the range of possible values parameters to sensible values given the assumptions mentioned above\n",
    "    minimiser.limits = [(1.0, 2.0), (19.0, 21.0), (0.06, 0.2)]\n",
    "    results = minimiser.migrad()\n",
    "\n",
    "    # Return list of paramer values in the same order as the initial parameter dictionary\n",
    "    return get_optimised_values(results, initial_parameters.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using these functions, we can now loop over it 100 times to obtain out optimised parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters forgen and fit function for testing\n",
    "n_events = 10000\n",
    "truth_parameters = {\n",
    "    \"tau\":              1.5,\n",
    "    \"delta_mass\":       20.0,\n",
    "    \"V\":                0.1,\n",
    "}\n",
    "n_toy_datasets = 100\n",
    "\n",
    "# Define empty lists to hold optimised parameters (Three nested lists to contain each parameter)\n",
    "optimised_parameters_dict = {\n",
    "    \"optimised_tau\":          [],\n",
    "    \"optimised_delta_mass\":   [],\n",
    "    \"optimised_V\":            [],\n",
    "}\n",
    "\n",
    "# Loop over fitting function 100 times\n",
    "for _ in range(n_toy_datasets):\n",
    "    # Generate fit and find optimised params\n",
    "    optimised_parameters = generate_and_fit_dataset(bounds=X_BOUNDS, n_events=n_events, truth_parameters=truth_parameters)\n",
    "\n",
    "    # Append each optimised parameter to list in dictionary\n",
    "    for idx, key in enumerate(optimised_parameters_dict):\n",
    "        optimised_parameters_dict[key].append(optimised_parameters[idx])\n",
    "\n",
    "# Convert lists in dictionary to numpy arrays\n",
    "for key in optimised_parameters_dict:\n",
    "    optimised_parameters_dict[key] = np.array(optimised_parameters_dict[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now compute the precision of each of our optimised parameters by taking the mean value of the optimised parameter lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the precision\n",
    "tau_precision = optimised_parameters_dict[\"optimised_tau\"].mean()\n",
    "delta_mass_precision = optimised_parameters_dict[\"optimised_delta_mass\"].mean()\n",
    "V_precision = optimised_parameters_dict[\"optimised_V\"].mean()\n",
    "\n",
    "# Output precision of each parameter\n",
    "print(f\"The precision on the tau parameter for our MC simulation is {tau_precision:.2f} arbitrary units\\n\")\n",
    "print(f\"The precision on the delta mass parameter for our MC simulation is {delta_mass_precision:.2f} arbitrary units\\n\")\n",
    "print(f\"The precision on the V parameter for our MC simulation is {V_precision:.2f} arbitrary units\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have 100 sets of optimised parameters, we can plot the distributuion for each optimised parameters and see how they are distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3,1)\n",
    "\n",
    "for idx, key in enumerate(optimised_parameters_dict):\n",
    "    # Plot a histogram of the optiised value\n",
    "    _ = axes[idx].hist(optimised_parameters_dict[key], bins=100, histtype=\"step\")\n",
    "    axes[idx].set_ylabel(\"Counts\")\n",
    "    axes[idx].set_xlabel(key)\n",
    "fig.suptitle(\"Histogram of optimised parameters for 100 toy datasets\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the bias on the optimised parameters as the diference between the optimised parameters and the MC truth values. Hence we compute the bias on the optimised parameters\n",
    "\n",
    "We notice on the there is a significant bias on the optimised parameters of tau. This is likely due to the fact that the pdf we are generating is truncated from $\\in [0, 10]$, while the pdf should go to positive infinity. As a result, our MC toy datasets will generate more events within the bounds than the actual dataset, hence skewing out fits.\n",
    "\n",
    "Given that the value of $\\tau$ is the decay parameter, it is the most affected by a change in overall amplitude of the MC dataset compared to the angular frequency and amplitude of the harmonic occilation. As a result it is the parameter tat we expect to be skewed the most."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the bias\n",
    "tau_bias = abs(truth_parameters[\"tau\"] - tau_precision)\n",
    "delta_mass_bias = abs(truth_parameters[\"delta_mass\"] - delta_mass_precision)\n",
    "V_bias = abs(truth_parameters[\"V\"] - V_precision)\n",
    "\n",
    "# Print the biases on the precision\n",
    "print(f\"The bias of the tau parameter for our MC simulation is {tau_bias:.3g}\\n\")\n",
    "print(f\"The bias of the delta mass parameter for our MC simulation is {delta_mass_bias:.3g}\\n\")\n",
    "print(f\"The bias of the V parameter for our MC simulation is {V_bias:.3g} arbitrary units\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values for the optimised parameters we are obtaining are drawn from a gaussian distribution. Hence with this, we can obtain the presicion on the bias (uncertanty) on the precision (mean) of our optimised parameters by computing the standard error on the mean for a gaussian:\n",
    "\n",
    "\\begin{equation}\n",
    "\\delta\\mu = \\frac{\\mu}{\\sqrt{N}}\n",
    "\\end{equation}\n",
    "\n",
    "where N is the number of optimised parameters (given by the number of toy expewriments we ran).\n",
    "\n",
    "Below we compute and print the precision on the bias of the parameters for our MC simualtions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the bias on the bias\n",
    "tau_error = optimised_parameters_dict[\"optimised_tau\"].mean() / np.sqrt(n_toy_datasets)\n",
    "delta_mass_error = optimised_parameters_dict[\"optimised_delta_mass\"].mean() / np.sqrt(n_toy_datasets)\n",
    "V_error = optimised_parameters_dict[\"optimised_V\"].mean() / np.sqrt(n_toy_datasets)\n",
    "\n",
    "# Output precision of each parameter\n",
    "print(f\"The precision and the precision on the bias of the tau parameter for our MC simulation is {tau_precision:.2f} +/- {tau_error:.2g} arbitrary units\\n\")\n",
    "print(f\"The precision and the precision on the bias of the delta mass parameter for our MC simulation is {delta_mass_precision:.2f} +/- {delta_mass_error:.2f} arbitrary units\\n\")\n",
    "print(f\"The precision and the precision on the bias of the V parameter for our MC simulation is {V_precision:.3f} +/- {V_error:.3f} arbitrary units\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now require a class which will randomly generate values acording to an exponential distribution. As such, we will create a similar class as the one previously which hill inheret from ProbabilityDensityFunction and use the exponential random number generator from the random library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Exponential(ProbabilityDensityFunction):\n",
    "    \"\"\"\n",
    "    Class that will generate a random value according to an exponential decay\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, decayConstant, bounds):\n",
    "\n",
    "        # Initialise parent class\n",
    "        super().__init__(bounds)\n",
    "\n",
    "        # Initialise class variables\n",
    "        self.decayConstant = decayConstant\n",
    "\n",
    "        # Define normalisation of exponential between bounds\n",
    "        self.normalisationFactor = self.decayConstant * (1 - np.exp(-10/self.decayConstant)) \n",
    "\n",
    "    def evaluate(self, x,):\n",
    "        \"\"\"\n",
    "        Evaluate the linear function of the distribution\n",
    "        NOTE: Returns un-normalised values\n",
    "        \"\"\"\n",
    "        \n",
    "        return np.exp(-x/self.decayConstant) \n",
    "\n",
    "    def _evaluateOptimised(self, t):\n",
    "        \"\"\"\n",
    "        Evatuate the function of the distribution when the t value passed is not a numpy array.\n",
    "        Optimised for operations using python's fundamental types. This method is used in this class when generating\n",
    "        random points from the distribution\n",
    "        NOTE: Returns un-normalised values\n",
    "        \"\"\"\n",
    "\n",
    "        return math.exp(-t/self.decayConstant)\n",
    "\n",
    "    def next(self,):\n",
    "        \"\"\"\n",
    "        Generate a single random variable according to the class' distribution using the box method.\n",
    "        Will return and append generated variable to mass list.\n",
    "        \"\"\"\n",
    "\n",
    "        x = random.expovariate(1/self.decayConstant)\n",
    "        self.mass.append(x)\n",
    "        return x \n",
    "\n",
    "    def setParameters(self, decayConstant=None):\n",
    "        \"\"\"\n",
    "        Set passed variables as parameters for pdf\n",
    "        \"\"\"\n",
    "\n",
    "        # Use default values for parameters of none are passed through kwargs\n",
    "        if not decayConstant == None:                   self.decayConstant = decayConstant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now create a seperate class which inherits the ProbabilityDensityFunction and contains a pdf for the decay function + a background exponential decay function (with a longer lifetime)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecayWithBackground(ProbabilityDensityFunction):\n",
    "    \"\"\"\n",
    "    Class that will generate a random distribution consisting of a Gaussian + Short lifetime exponential signal and a \n",
    "    longer lifetime \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, backgroundFraction, tau, deltaMass, V, decayConstant , bounds,):\n",
    "        \n",
    "        # Initialise parent class\n",
    "        super().__init__(bounds)\n",
    "\n",
    "        self.backgroundFraction = backgroundFraction\n",
    "    \n",
    "        # Initialise pdf objects\n",
    "        self.signal = HarmonicWithDecay(tau, deltaMass, V, bounds)\n",
    "        self.background = Exponential(decayConstant, bounds)\n",
    "\n",
    "    def evaluate(self, x,):\n",
    "        \"\"\"\n",
    "        Evaluate the function of the distribution\n",
    "        \"\"\"\n",
    "\n",
    "        # Compute the normalisation for thje signal (the background value is already normalised)\n",
    "        normalisationSignal = self.signal.integrate(self.boundMin, self.boundMax)\n",
    "        normalisationBackground = self.background.normalisationFactor\n",
    "        return (1-self.backgroundFraction)*self.signal.evaluate(x,)/normalisationSignal + \\\n",
    "                self.backgroundFraction*self.background.evaluate(x,)/normalisationBackground\n",
    "\n",
    "    def next(self,):\n",
    "        \"\"\"\n",
    "        Generate a single random variable according to the class' distribution using numpy.random.normal method\n",
    "        Will return and append generated variable to mass list.\n",
    "        \"\"\"\n",
    "\n",
    "        randomProbability = random.uniform(0.0, 1.0)\n",
    "\n",
    "        if (randomProbability <= self.backgroundFraction):\n",
    "            # Draw x from background distribution\n",
    "            filteredX = self.background.next()\n",
    "        else:\n",
    "            # Draw x from signal distribution\n",
    "            filteredX, _ = self.signal.next()\n",
    "        \n",
    "        # Add filtered x to mass list irrespective of what distribution it was drawn from\n",
    "        self.mass.append(filteredX)\n",
    "        return filteredX\n",
    "\n",
    "    def setParameters(self, backgroundFraction=None, tau=None, deltaMass=None, V=None, decayConstant=None):\n",
    "        \"\"\"\n",
    "        Set passed variables as parameters for pdf\n",
    "        \"\"\"\n",
    "\n",
    "        # Use default values for parameters of none are passed through kwargs\n",
    "        if not backgroundFraction == None:      self.backgroundFraction = backgroundFraction\n",
    "        if not tau == None:                     self.signal.tau = tau\n",
    "        if not deltaMass == None:               self.signal.deltaMass = deltaMass       \n",
    "        if not V == None:                       self.signal.V = V   \n",
    "        if not decayConstant == None:           self.background.decayConstant = decayConstant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now create 4 datasets using the DecayWithBackground class with varying background fractions. The values for the background functions are:\n",
    "* background fraction = 0.0\n",
    "* background fraction = 0.1\n",
    "* background fraction = 0.2\n",
    "* background fraction = 0.3\n",
    "* background fraction = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define number of events in each toy dataset\n",
    "n_events = 100000\n",
    "\n",
    "# Add truth value of decay constant for additional expponential to the truth parameter dictionary\n",
    "truth_parameters[\"decay_constant\"] = 8.0\n",
    "\n",
    "# Define parameters to be used for this question\n",
    "background_fraction_values = [0.0, 0.1, 0.2, 0.3, 0.4,]\n",
    "\n",
    "# Define empty dictionary to hold datasets from DacayWithSignal class\n",
    "decay_with_background_datasets = {}\n",
    "\n",
    "# Initialise DecayWithSignal class\n",
    "# Note: We use the truth values we defined for the previous question\n",
    "decay_with_signal = DecayWithBackground(\n",
    "    backgroundFraction = 0.0,\n",
    "    tau = truth_parameters[\"tau\"],\n",
    "    deltaMass = truth_parameters[\"delta_mass\"],\n",
    "    V = truth_parameters[\"V\"],\n",
    "    decayConstant = truth_parameters[\"decay_constant\"],\n",
    "    bounds = X_BOUNDS\n",
    ")\n",
    "\n",
    "# Loop over all background fraction values and create a detaset using each value\n",
    "# We will store the dataset in it's corresponding dictionary using the value of the signal fraction as the key\n",
    "for background_fraction in background_fraction_values:\n",
    "    \n",
    "    # Set the value of the background fraction in the pdf class\n",
    "    decay_with_signal.setParameters(backgroundFraction=background_fraction)\n",
    "    \n",
    "    # Generate dataset\n",
    "    for _ in range(n_events):\n",
    "        decay_with_signal.next()\n",
    "    \n",
    "    # Get and save dataset in dictionary. \n",
    "    # Note: We flush the mass array within the object after each dataset is created\n",
    "    decay_with_background_datasets[str(background_fraction)] = decay_with_signal.getMass(flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now plot histograms for all 4 datasets to visualise the difference the additional exponantial backround term affects the shape of the toy datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define config values for the folowing plot\n",
    "fig, axes = plt.subplots(1, 5, sharey=True)\n",
    "fig.set_size_inches(20, 4)\n",
    "colours = [\"black\", \"blue\", \"green\", \"purple\", \"red\", \"magenta\"]\n",
    "n_bins = 100\n",
    "\n",
    "# Iterate over each dataset and plot a hstogram of the counts\n",
    "for idx, dataset in enumerate(decay_with_background_datasets.values()):\n",
    "    # Plot histogram\n",
    "    axes[idx].hist(dataset, bins=n_bins, histtype=\"step\", color=colours[idx], range=(0.0, 10.0), label=f\"background fraction = {list(decay_with_background_datasets.keys())[idx]}\")\n",
    "    axes[idx].set_xlabel(\"time, t (arbitrary units)\")\n",
    "    axes[idx].legend()\n",
    "\n",
    "axes[0].set_ylabel(f\"Frequency of events (counts)\")\n",
    "axes[0].set_xlabel(\"time, t (arbitrary units)\")\n",
    "fig.suptitle(\"Toy dataset histograms for different exponential backgrounds\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above plot showsa what we would expect. As the background fraction becomes grater, the tail of the overall distribution begins to become longer, as the exponential background with the longer decay time becomes more significant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now look to fit each one of the above datasets using the DecayWithBackgound class and minuit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an empty dictionary to hold the optimised parameters of DecayWithBackground for all five datasets\n",
    "optimised_parameters = {                             # Overwrites previous optimised parameter dictionary\n",
    "    \"tau\":                  [],\n",
    "    \"delta_mass\":           [],\n",
    "    \"V\":                    [],\n",
    "}\n",
    "\n",
    "# Define an empty dictionary to hold the errors on the optimised parameters of DecayWithBackground for all five datasets\n",
    "optimised_parameter_errors = {                            \n",
    "    \"tau\":                  [],\n",
    "    \"delta_mass\":           [],\n",
    "    \"V\":                    [],\n",
    "}\n",
    "\n",
    "# Define dictionary with initial guesses for fits\n",
    "initial_parameters = {\n",
    "    \"tau\"       : 1.5,\n",
    "    \"deltaMass\" : 20.0,\n",
    "    \"V\"         : 0.1,\n",
    "}\n",
    "\n",
    "# loop over all datasets, fit the datasets and store the optimised parameters\n",
    "for idx, dataset in enumerate(decay_with_background_datasets.values()):\n",
    "\n",
    "    # Initialise pdf and fit statistic for fitting dataset\n",
    "    # Only pass first three values of truth parameters as they are the parameters for the the HarmonicWithDecay class \n",
    "    pdf = HarmonicWithDecay(*list(truth_parameters.values())[:-1], bounds=X_BOUNDS)        \n",
    "\n",
    "    # Minimise the events\n",
    "    negative_log_likelihood = NegativeLogLikelihood(pdf, dataset)\n",
    "    minimiser = Minuit(negative_log_likelihood.evaluate, **initial_parameters)\n",
    "\n",
    "    # Limit the range of possible values parameters to sensible values given the assumptions mentioned above\n",
    "    minimiser.errordef = 0.5\n",
    "    results = minimiser.migrad()\n",
    "\n",
    "    # Store value of optimised parameter in corresponding dictionary\n",
    "    optimised_parameters[\"tau\"].append(results.values[\"tau\"])\n",
    "    optimised_parameters[\"delta_mass\"].append(results.values[\"deltaMass\"])\n",
    "    optimised_parameters[\"V\"].append(results.values[\"V\"])\n",
    "\n",
    "    # Store the errors on the optimised parameters in corresponding dictionary\n",
    "    optimised_parameter_errors[\"tau\"].append(results.errors[\"tau\"])\n",
    "    optimised_parameter_errors[\"delta_mass\"].append(results.errors[\"deltaMass\"])\n",
    "    optimised_parameter_errors[\"V\"].append(results.errors[\"V\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot the histograms of the data allong with their fit to see if we have achieved a correct fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define config values for the folowing plot\n",
    "fig, axes = plt.subplots(1, 5, sharey=True)\n",
    "fig.set_size_inches(20, 4)\n",
    "colours = [\"black\", \"blue\", \"green\", \"purple\", \"red\", \"magenta\"]\n",
    "n_bins = 100\n",
    "\n",
    "# Iterate over each dataset and plot a hstogram of the counts\n",
    "for idx, dataset in enumerate(decay_with_background_datasets.values()):\n",
    "    \n",
    "    # Set value of parameter for remaining parameters\n",
    "    pdf.setParameters(tau=optimised_parameters[\"tau\"][idx])\n",
    "    pdf.setParameters(deltaMass=optimised_parameters[\"delta_mass\"][idx])\n",
    "    pdf.setParameters(V=optimised_parameters[\"V\"][idx])\n",
    "\n",
    "    # Define plotting axes\n",
    "    ax = axes.flatten()[idx]\n",
    "    \n",
    "    # Plot histogram\n",
    "    ax.hist(dataset, bins=n_bins, histtype=\"step\", color=colours[idx], label=\"Toy dataset\", density=True, range=(X_BOUNDS))\n",
    "    ax.plot(t, pdf.evaluate(t)/pdf.integrate(X_BOUNDS), c=colours[idx], ls=\"--\", label=\"Fit\")\n",
    "    ax.set_title(f\"background fraction = {list(decay_with_background_datasets.keys())[idx]}\")\n",
    "    ax.set_ylabel(f\"Num of events\")\n",
    "    ax.set_xlabel(\"Time, t (arbitrary units)\")\n",
    "    ax.legend()\n",
    "\n",
    "fig.suptitle(\"Toy dataset histograms for different exponential backgrounds\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that when the background fraction is 0, the fit using the HarmonicWithDecay model does a good job at fitting the MC toy datasets. However, as the background fraction begins to increase, we start to that the fit begins to skew more towards a an exponential with a longer decay time. This is likely due to minuit fitting the tau parameter of HarmonicWithDecay to be longer, in an attempt to fit the background's longer decay length more.\n",
    "\n",
    "This however results in the fit line moving away from the actual distribution, hence worseing the fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now plot the value and errors of the optimised parameters for the different datasets to see compare how the fits preform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define config parameters for the plot\n",
    "fig, axes = plt.subplots(len(optimised_parameters.keys()), 1, sharex=True)\n",
    "\n",
    "# Plot each of the optimised parameters along with corresponding errors\n",
    "for idx, key in enumerate(optimised_parameters.keys()):\n",
    "    axes[idx].errorbar(background_fraction_values, optimised_parameters[key], yerr=optimised_parameter_errors[key], fmt=\"gx\", label=\"Fitted value\", capsize=3.0,)\n",
    "    axes[idx].axhline(truth_parameters[key], 0.02, 0.98, ls=\"--\", lw=1.0, label=\"MC truth\", c=\"purple\",)\n",
    "    axes[idx].set_ylabel(key)\n",
    "    axes[idx].set_xticks(background_fraction_values)\n",
    "    axes[idx].legend()\n",
    "\n",
    "fig.suptitle(\"Optimised parameter value vs fixed background function\")\n",
    "fig.tight_layout()\n",
    "\n",
    "# Only plot on last axis\n",
    "axes[-1].set_xlabel(\"Fixed background fraction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the best fit parameters for the delta mass and V are largely uncorrelated when using the HarminicWithDecay model to fit the HarmonicWithModel + Background MC data for low background fractions. Hence the bias on the optimised delta mass and V parameters are largly unchanged as the background mass increases.\n",
    "\n",
    "Meanwhile, we see that thre is a strong positive correlation between the optimised tau parameter and the background fraction with the value diverging from the MC truth value. This is to be expected as increasin gthe background fraction will smear the HarminicWithDecay distribution into an exponential decay with a longer lifetime. Hence, the optimiser will find that a larger tau parameter will minimise the negative log likelyhood as it attempts to fit the smeared distribution. \n",
    "\n",
    "We also notce that the errors for the delta mass and V oiptimised parameters are relativly large. This is likely a result of the solver using a model that does not correctly describe the data. As a result, the slover finds that the range of delta mass and  V values that can minimise the negative log likelyhood within 0.5 $\\sigma$ is large, resulting in the large errors.\n",
    "\n",
    "From this we can conclude that as the background fraction increases, so will the bias on the optimised tau fit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
